# Stereoscopic vision and emotional face processing
This code was created as part of a Master's Thesis at the Max Planck Institute for Human Cognitive and Brain Sciences and the University of Oldenburg. We combined immersive Virtual Reality (VR) technology with EEG measurements to investigate the recognition and neurophysiological responses to digital humans' emotional facial expressions (neutral, happy, angry, and surprise) - contrasting stereoscopic and monoscopic viewing conditions. The git repository provides the code to analyze the EEG and behavioral data of the study. 

<img src="/visualisation/AvatarMatrix.png" width="260" height="200">

Code based on this research:

ðŸ“œ **Ammara Nasim; Felix Klotzsche; Prof. Dr. Werner Sommer; Prof. Dr. Jochem W. Rieger; Michael Gaebler**

https://tinyurl.com/VRstereofem-Poster-MBBS

ðŸ“œ **Felix Klotzsche; Ammara Nasim; Simon M. Hofmann; Arno Villringer; Vadim V. Nikulin; Werner Sommer; Michael Gaebler**

https://www.cbs.mpg.de/2106779/a27_klotzsche.pdf

https://jov.arvojournals.org/article.aspx?articleid=2792647 


